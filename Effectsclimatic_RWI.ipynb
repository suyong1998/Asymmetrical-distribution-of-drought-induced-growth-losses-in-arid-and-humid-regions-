{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c655cc-9293-4301-9bc8-8c7161eb39cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "from scipy import stats\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import geopandas as gpd\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from geopandas.tools import overlay\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import linregress\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f449c17-5b4c-4e2d-95ed-d074e1c7f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_site = pd.read_csv('itrdb_dem_landconr_values.csv')\n",
    "df_site['year_difference']=df_site['end_year']-df_site['strat_year']\n",
    "df_siteEPS = df_site[(df_site['eps'] >= 0.85) & (df_site['snr'] > 3) & \n",
    "            (df_site['LandCver'] == 10) & (df_site['end_year'] >= 1901) &\n",
    "                (df_site['year_difference'] >= 30) & (df_site['end_year'] <= 2022)]\n",
    "species_counts = df_siteEPS['Tree_Speci'].value_counts()\n",
    "selected_species = species_counts[species_counts >= 20].index.tolist()\n",
    "len(selected_species)\n",
    "df_siteEPS_M_S = df_siteEPS[df_siteEPS['Tree_Speci'].isin(selected_species)]\n",
    "df_siteEPS_M_S1 = df_siteEPS_M_S.loc[:,('site','DEM','Latitude','Longitude','Tree_Speci','end_year','strat_year','ai_v3')]\n",
    "conditions = [\n",
    "    df_siteEPS_M_S1['ai_v3'] < 0.65,\n",
    "    df_siteEPS_M_S1['ai_v3'] >= 0.65\n",
    "]\n",
    "choices = ['Arid', 'Humid']\n",
    "df_siteEPS_M_S1['AI_Class'] = np.select(conditions, choices)\n",
    "df_siteEPS_M_S1.to_csv('sample_site.csv',index=False)\n",
    "print(df_siteEPS_M_S1['AI_Class'].value_counts())\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 12\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.figure(figsize=(2,3.5),dpi=100)\n",
    "ai_class_counts = df_siteEPS_M_S1['AI_Class'].value_counts()\n",
    "ai_class_counts.plot(kind='bar', color='skyblue')\n",
    "plt.xlabel('Aridity Class',fontsize=12)\n",
    "plt.ylabel('Count',fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.savefig('Fig1C.jpg',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48fed5-1473-4d7e-84b0-f9a85ab70b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_species = pd.read_excel('40tree.xlsx')\n",
    "df_species_O = df_species.sort_values('order')\n",
    "species_dict = dict(zip(df_species['Tree_Speci'], df_species['Clade']))\n",
    "df_siteEPS_M_S1['Species_group'] = df_siteEPS_M_S1['Tree_Speci'].map(species_dict)\n",
    "df_siteEPS_M_S1['Species_group'] = df_siteEPS_M_S1['Species_group'].fillna('Unknown')\n",
    "\n",
    "df = pd.DataFrame(index=range(1901, 2016))\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "\n",
    "for species in df_siteEPS_M_S1['Tree_Speci'].unique():\n",
    "    df_species = df_siteEPS_M_S1[df_siteEPS_M_S1['Tree_Speci'] == species]\n",
    "\n",
    "    for year in range(1901, 2016):\n",
    "        df.loc[year, species] = len(df_species[df_species['end_year'] >= year])\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "species_groups = df_siteEPS_M_S1[['Tree_Speci', 'Species_group']].drop_duplicates()\n",
    "species_groups = species_groups.set_index('Tree_Speci')\n",
    "\n",
    "new_order = df_species_O[df_species_O['Tree_Speci'].isin(df.columns)]['Tree_Speci']\n",
    "df = df.reindex(columns= new_order)\n",
    "\n",
    "n_angiosperm = len(species_groups[species_groups['Species_group'] == 'Angiosperms'])\n",
    "n_gymnosperm = len(species_groups[species_groups['Species_group'] == 'Gymnosperms'])\n",
    "\n",
    "colors = plt.cm.RdBu(np.linspace(0, 0.5, n_gymnosperm).tolist() + np.linspace(0.5, 1, n_angiosperm).tolist())\n",
    ")\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = df.plot(kind='bar', width=0.8, stacked=True, colormap=cmap, ax=plt.gca())\n",
    "\n",
    "plt.xlabel('Year', fontsize=18)\n",
    "plt.ylabel('Number of site', fontsize=18)\n",
    "\n",
    "xticks = [1901, 1920, 1940, 1960, 1980, 2000, 2015]\n",
    "ax.set_xticks([df.index.get_loc(i) for i in xticks])\n",
    "ax.set_xticklabels(xticks)\n",
    "\n",
    "ax.legend().remove()\n",
    "\n",
    "norm = plt.Normalize(vmin=0, vmax=len(df.columns)-1)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([]) \n",
    "cbar = plt.colorbar(sm, ax=ax, pad=0.02,)\n",
    "cbar.set_ticks(np.arange(len(df.columns)))\n",
    "cbar.set_ticklabels(df.columns,fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig2b.jpg', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a886a3-564d-41c7-9019-0e21ad1c57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df_siteEPS_M_S1, geometry=gpd.points_from_xy(df_siteEPS_M_S1.Longitude, df_siteEPS_M_S1.Latitude))\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 12\n",
    "ax.set_ylim(-20, 90)\n",
    "world.boundary.plot(ax=ax, linewidth=0.5, color='black')\n",
    "gdf['Tree_Speci'] = gdf['Tree_Speci'].astype('category')\n",
    "species_groups = df_siteEPS_M_S1[['Tree_Speci', 'Species_group']].drop_duplicates()\n",
    "gdf['Species_group_rank'] = gdf['Tree_Speci'].map(species_groups.set_index('Tree_Speci')['Species_group'].replace({'Angiosperms': 0, 'Gymnosperms': 1}))\n",
    "gdf = gdf.sort_values(by='Species_group_rank')\n",
    "n_angiosperm = len(species_groups[species_groups['Species_group'] == 'Angiosperms'])\n",
    "n_gymnosperm = len(species_groups[species_groups['Species_group'] == 'Gymnosperms'])\n",
    "colors = plt.cm.RdBu(np.linspace(0, 0.5, n_gymnosperm).tolist() + np.linspace(0.5, 1, n_angiosperm).tolist())\n",
    "cmap = ListedColormap(colors)\n",
    "gdf.plot(column='Tree_Speci', ax=ax, legend=False, cmap=cmap, markersize=4)\n",
    "ax.grid(True, linestyle='--', color='black',linewidth=0.4)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"bottom\", size=\"8%\", pad=0.3)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=0, vmax=len(gdf['Tree_Speci'].cat.categories)-1))\n",
    "cbar = fig.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "sorted_categories = new_order\n",
    "cbar.set_ticks(np.arange(len(sorted_categories)))\n",
    "cbar.set_ticklabels(sorted_categories)\n",
    "cbar.ax.set_xticklabels(cbar.ax.get_xticklabels(), rotation=90, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Distribution tree species.jpg',dpi=600,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91474d28-827f-4c8a-b216-166bfeddefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax = pd.read_csv('annual_Tmax.csv').dropna()\n",
    "list_site = pd.merge(df_siteEPS_M_S1,Tmax,on='site')['site']\n",
    "list_site = pd.merge(df_siteEPS_M_S1,Tmax,on='site')['site']\n",
    "from scipy.stats import linregress\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "list_sites = []\n",
    "list_β_Tmax = []\n",
    "for i in tqdm(range(len(list_site)), desc=\"Calculating Pearson Correlation\"):\n",
    "    site_i = list_site[i]\n",
    "    std_path = 'E:\\experiment\\DTR_AI_growth\\data\\ITRDB\\FZS_STD_crn\\\\'+ site_i + '.rwlcrn.csv'\n",
    "    df_rwl_i = pd.read_csv(std_path, index_col=0)\n",
    "    year_i = df_rwl_i.index.to_list()\n",
    "    list_range = [i for i in range(1901, 2016)]\n",
    "    intersection = list(set(year_i) & set(list_range))\n",
    "    if len(intersection)>= 10:\n",
    "        std_i = df_rwl_i.loc[intersection,'std'].to_list()\n",
    "        Tmax_i = Tmax.set_index('site').loc[site_i,[f'{year}' for year in intersection]]\n",
    "        Tmax_i = np.array(Tmax_i).reshape(-1, 1)\n",
    "        model = LinearRegression()\n",
    "        model.fit(Tmax_i, std_i)\n",
    "        list_β_Tmax.append(model.coef_)\n",
    "        list_sites.append(site_i)\n",
    "df_tmaxβ = pd.DataFrame(list_β_Tmax)\n",
    "df_tmaxβ.columns = ['β']\n",
    "df_tmaxβ.insert(0,'site',list_sites)\n",
    "df_tmaxβcs = pd.merge(df_siteEPS_M_S1,df_tmaxβ,on='site')\n",
    "def calculate_confidence_interval(df, column):\n",
    "    lower_bound = np.percentile(df[column], 2.5)\n",
    "    upper_bound = np.percentile(df[column], 97.5)\n",
    "    df_95 = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    mean_value = np.mean(df_95[column])\n",
    "    print(\"95% Confidence Interval ({}): [{:.4f}, {:.4f}]\".format(column, lower_bound, upper_bound))\n",
    "    print(\"Mean ({}): {:.4f}\".format(column, mean_value))\n",
    "    return df_95\n",
    "grouped = df_tmaxβcs.groupby('AI_Class')\n",
    "anova_results_dr = {}\n",
    "anova_results_wr = {}\n",
    "group_humid = grouped.get_group('Humid')\n",
    "group_arid = grouped.get_group('Arid')\n",
    "group_humid95 = calculate_confidence_interval(group_humid, 'β')\n",
    "group_arid95 = calculate_confidence_interval(group_arid, 'β')\n",
    "\n",
    "group_95_Tmax = pd.concat([group_humid95,group_arid95],axis=0)\n",
    "group_95_Tmax['Climate factors'] = 'Tmax'\n",
    "f_statistic_dr, p_value_dr = f_oneway(group_humid95['β'], group_arid95['β'])\n",
    "anova_results_dr['β'] = {'F-statistic': f_statistic_dr, 'p-value': p_value_dr}\n",
    "for key, value in anova_results_dr.items():\n",
    "    print(f\"{key}: F-statistic: {value['F-statistic']}, p-value: {value['p-value']}\")\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "plt.figure(figsize=(4,3.5),dpi=100)\n",
    "palette=[(0/255, 92/255, 230/255),(255/255, 0/255, 0/255)]\n",
    "alpha = 0.5 \n",
    "sns.boxplot(x=\"AI_Class\", y=\"β\", data=group_95_Tmax,palette=palette\n",
    "            ,  fill=False, gap=.2, boxprops=dict(alpha=alpha)\n",
    "            , whiskerprops=dict(alpha=alpha)\n",
    "            , capprops=dict(alpha=alpha), medianprops=dict(alpha=alpha))\n",
    "plt.axhline(0, color='black', linestyle='--',linewidth=.6)\n",
    "plt.yticks(np.arange(-0.4, 0.5, 0.2)) \n",
    "plt.legend().set_visible(False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('β Tmax-Growth',fontsize=18)\n",
    "plt.text(0.5, 0.37, '***', ha='center', va='center')\n",
    "plt.text('Humid', 0.33,  f'n= {len(group_humid95)}', ha='center', va='center')\n",
    "plt.text('Arid', 0.33,  f'n= {len(group_arid95)}', ha='center', va='center')\n",
    "plt.savefig('FigS7a.jpg',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad9c56-22f0-42b2-878e-ef70bd8f8408",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmin = pd.read_csv('annual_Tmin.csv').dropna()\n",
    "list_site = pd.merge(df_siteEPS_M_S1,Tmin,on='site')['site']\n",
    "from scipy.stats import linregress\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "list_sites = []\n",
    "list_β_Tmin = []\n",
    "for i in tqdm(range(len(list_site)), desc=\"Calculating Pearson Correlation\"):\n",
    "    site_i = list_site[i]\n",
    "    std_path = 'E:\\experiment\\DTR_AI_growth\\data\\ITRDB\\FZS_STD_crn\\\\'+ site_i + '.rwlcrn.csv'\n",
    "    df_rwl_i = pd.read_csv(std_path, index_col=0)\n",
    "    year_i = df_rwl_i.index.to_list()\n",
    "    list_range = [i for i in range(1901, 2016)]\n",
    "    intersection = list(set(year_i) & set(list_range))\n",
    "    if len(intersection)>= 10:\n",
    "        std_i = df_rwl_i.loc[intersection,'std'].to_list()\n",
    "        Tmin_i = Tmin.set_index('site').loc[site_i,[f'{year}' for year in intersection]]\n",
    "        Tmin_i = np.array(Tmin_i).reshape(-1, 1)\n",
    "        model = LinearRegression()\n",
    "        model.fit(Tmin_i, std_i)\n",
    "        list_β_Tmin.append(model.coef_)\n",
    "        list_sites.append(site_i)\n",
    "df_β_Tmin = pd.DataFrame(list_β_Tmin)\n",
    "df_β_Tmin.columns = ['β']\n",
    "df_β_Tmin.insert(0,'site',list_sites)\n",
    "df_β_Tmincs = pd.merge(df_siteEPS_M_S1,df_β_Tmin,on='site')\n",
    "grouped = df_β_Tmincs.groupby('AI_Class')\n",
    "anova_results_dr = {}\n",
    "anova_results_wr = {}\n",
    "group_humid = grouped.get_group('Humid')\n",
    "group_arid = grouped.get_group('Arid')\n",
    "group_humid95 = calculate_confidence_interval(group_humid, 'β')\n",
    "group_arid95 = calculate_confidence_interval(group_arid, 'β')\n",
    "\n",
    "group_95_tmin = pd.concat([group_humid95,group_arid95],axis=0)\n",
    "group_95_tmin['Climate factors'] = 'Tmin'\n",
    "\n",
    "f_statistic_dr, p_value_dr = f_oneway(group_humid['β'], group_arid['β'])\n",
    "anova_results_dr['β'] = {'F-statistic': f_statistic_dr, 'p-value': p_value_dr}\n",
    "\n",
    "for key, value in anova_results_dr.items():\n",
    "    print(f\"{key}: F-statistic: {value['F-statistic']}, p-value: {value['p-value']}\")\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "plt.figure(figsize=(4,3.5),dpi=100)\n",
    "palette=[(0/255, 92/255, 230/255),(255/255, 0/255, 0/255)]\n",
    "alpha = 0.5 \n",
    "sns.boxplot(x=\"AI_Class\", y=\"β\", data=group_95_tmin,palette=palette\n",
    "            ,  fill=False, gap=.2, boxprops=dict(alpha=alpha)\n",
    "            , whiskerprops=dict(alpha=alpha)\n",
    "            , capprops=dict(alpha=alpha), medianprops=dict(alpha=alpha))\n",
    "plt.axhline(0, color='black', linestyle='--',linewidth=.6)\n",
    "plt.yticks(np.arange(-0.4, 0.5, 0.2)) \n",
    "plt.legend().set_visible(False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('β Tmin-Growth',fontsize=18)\n",
    "plt.text(0.5, 0.37, '***', ha='center', va='center')\n",
    "plt.text('Humid', 0.33,  f'n= {len(group_humid95)}', ha='center', va='center')\n",
    "plt.text('Arid', 0.33,  f'n= {len(group_arid95)}', ha='center', va='center')\n",
    "plt.savefig('FigS7e.jpg',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485e3ee-5f3b-44c3-b2d4-43aa7e8923e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre = pd.read_csv('annual_pre.csv').dropna()\n",
    "list_site = pd.merge(df_siteEPS_M_S1,Pre,on='site')['site']\n",
    "list_sites = []\n",
    "list_β_Pre = []\n",
    "for i in tqdm(range(len(list_site)), desc=\"Calculating Pearson Correlation\"):\n",
    "    site_i = list_site[i]\n",
    "    std_path = 'E:\\experiment\\DTR_AI_growth\\data\\ITRDB\\FZS_STD_crn\\\\'+ site_i + '.rwlcrn.csv'\n",
    "    df_rwl_i = pd.read_csv(std_path, index_col=0)\n",
    "    year_i = df_rwl_i.index.to_list()\n",
    "    list_range = [i for i in range(1901, 2016)]\n",
    "    intersection = list(set(year_i) & set(list_range))\n",
    "    if len(intersection)>= 10:\n",
    "        std_i = df_rwl_i.loc[intersection,'std'].to_list()\n",
    "        Pre_i = Pre.set_index('site').loc[site_i,[f'{year}' for year in intersection]]\n",
    "        Pre_i = np.array(Pre_i).reshape(-1, 1)\n",
    "        model = LinearRegression()\n",
    "        model.fit(Pre_i, std_i)\n",
    "        list_β_Pre.append(model.coef_)\n",
    "        list_sites.append(site_i)\n",
    "\n",
    "df_β_Pre = pd.DataFrame(list_β_Pre)\n",
    "df_β_Pre.columns = ['β']\n",
    "df_β_Pre.insert(0,'site',list_sites)\n",
    "df_β_Precs = pd.merge(df_siteEPS_M_S1,df_β_Pre,on='site')\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "import matplotlib.pyplot as plt\n",
    "grouped = df_β_Precs.groupby('AI_Class')\n",
    "anova_results_dr = {}\n",
    "anova_results_wr = {}\n",
    "group_humid = grouped.get_group('Humid')\n",
    "group_arid = grouped.get_group('Arid')\n",
    "group_humid95 = calculate_confidence_interval(group_humid, 'β')\n",
    "group_arid95 = calculate_confidence_interval(group_arid, 'β')\n",
    "group_95_pre = pd.concat([group_humid95,group_arid95],axis=0)\n",
    "group_95_pre['Climate factors'] = 'Pre'\n",
    "f_statistic_dr, p_value_dr = f_oneway(group_humid95['β'], group_arid95['β'])\n",
    "anova_results_dr['β'] = {'F-statistic': f_statistic_dr, 'p-value': p_value_dr}\n",
    "for key, value in anova_results_dr.items():\n",
    "    print(f\"{key}: F-statistic: {value['F-statistic']}, p-value: {value['p-value']}\")\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "plt.figure(figsize=(4,3.5),dpi=100)\n",
    "palette=[(0/255, 92/255, 230/255),(255/255, 0/255, 0/255)]\n",
    "alpha = 0.5 \n",
    "sns.boxplot(x=\"AI_Class\", y=\"β\", data=group_95_pre,palette=palette\n",
    "            ,  fill=False, gap=.2, boxprops=dict(alpha=alpha)\n",
    "            , whiskerprops=dict(alpha=alpha)\n",
    "            , capprops=dict(alpha=alpha), medianprops=dict(alpha=alpha))\n",
    "plt.axhline(0, color='black', linestyle='--',linewidth=.6)\n",
    "plt.yticks(np.arange(-0.002, 0.005, 0.002)) \n",
    "plt.legend().set_visible(False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('β Pre-Growth',fontsize=18)\n",
    "plt.text(0.5, 0.0037, '***', ha='center', va='center')\n",
    "plt.text('Humid', 0.0033,  f'n= {len(group_humid95)}', ha='center', va='center')\n",
    "plt.text('Arid', 0.0033,  f'n= {len(group_arid95)}', ha='center', va='center')\n",
    "plt.savefig('Fig.S7F.jpg',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d07068-e513-4110-a1f1-886ec935dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Temp = pd.read_csv('annual_temp.csv').dropna()\n",
    "list_site = pd.merge(df_siteEPS_M_S1,Temp,on='site')['site']\n",
    "list_sites = []\n",
    "list_β_Temp = []\n",
    "for i in tqdm(range(len(list_site)), desc=\"Calculating Pearson Correlation\"):\n",
    "    site_i = list_site[i]\n",
    "    std_path = 'E:\\experiment\\DTR_AI_growth\\data\\ITRDB\\FZS_STD_crn\\\\'+ site_i + '.rwlcrn.csv'\n",
    "    df_rwl_i = pd.read_csv(std_path, index_col=0)\n",
    "    year_i = df_rwl_i.index.to_list()\n",
    "    list_range = [i for i in range(1901, 2016)]\n",
    "    intersection = list(set(year_i) & set(list_range))\n",
    "    if len(intersection)>= 10:\n",
    "        std_i = df_rwl_i.loc[intersection,'std'].to_list()\n",
    "        Temp_i = Temp.set_index('site').loc[site_i,[f'{year}' for year in intersection]]\n",
    "        Temp_i = np.array(Temp_i).reshape(-1, 1)\n",
    "        model = LinearRegression()\n",
    "        model.fit(Temp_i, std_i)\n",
    "        list_β_Temp.append(model.coef_)\n",
    "        list_sites.append(site_i)\n",
    "\n",
    "df_β_Temp = pd.DataFrame(list_β_Temp)\n",
    "df_β_Temp.columns = ['β']\n",
    "df_β_Temp.insert(0,'site',list_sites)\n",
    "df_β_Tempcs = pd.merge(df_siteEPS_M_S1,df_β_Temp,on='site')\n",
    "grouped = df_β_Tempcs.groupby('AI_Class')\n",
    "anova_results_dr = {}\n",
    "anova_results_wr = {}\n",
    "group_humid = grouped.get_group('Humid')\n",
    "group_arid = grouped.get_group('Arid')\n",
    "group_humid95 = calculate_confidence_interval(group_humid, 'β')\n",
    "group_arid95 = calculate_confidence_interval(group_arid, 'β')\n",
    "group_95_temp = pd.concat([group_humid95,group_arid95],axis=0)\n",
    "group_95_temp['Climate factors'] = 'temp'\n",
    "f_statistic_dr, p_value_dr = f_oneway(group_humid['β'], group_arid['β'])\n",
    "anova_results_dr['β'] = {'F-statistic': f_statistic_dr, 'p-value': p_value_dr}\n",
    "for key, value in anova_results_dr.items():\n",
    "    print(f\"{key}: F-statistic: {value['F-statistic']}, p-value: {value['p-value']}\")\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "plt.figure(figsize=(4,3.5),dpi=100)\n",
    "palette=[(0/255, 92/255, 230/255),(255/255, 0/255, 0/255)]\n",
    "alpha = 0.5 \n",
    "sns.boxplot(x=\"AI_Class\", y=\"β\", data=group_95_temp,palette=palette\n",
    "            ,  fill=False, gap=.2, boxprops=dict(alpha=alpha)\n",
    "            , whiskerprops=dict(alpha=alpha)\n",
    "            , capprops=dict(alpha=alpha), medianprops=dict(alpha=alpha))\n",
    "plt.axhline(0, color='black', linestyle='--',linewidth=.6)\n",
    "plt.yticks(np.arange(-0.4, 0.5, 0.2)) \n",
    "plt.legend().set_visible(False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('β Temp-Growth',fontsize=18)\n",
    "plt.text(0.5, 0.37, '***', ha='center', va='center')\n",
    "plt.text('Humid', 0.33,  f'n= {len(group_humid95)}', ha='center', va='center')\n",
    "plt.text('Arid', 0.33,  f'n= {len(group_arid95)}', ha='center', va='center')\n",
    "plt.savefig('FigS7C.jpg',dpi=300, bbox_inches='tight')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f3183-8d2f-4d11-836b-2563c6d82421",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = pd.read_csv('annual_dtr.csv').dropna()\n",
    "list_site = pd.merge(df_siteEPS_M_S1,dtr,on='site')['site']\n",
    "from scipy.stats import linregress\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.stats\n",
    "\n",
    "list_sites = []\n",
    "list_β_dtr = []\n",
    "list_R = []\n",
    "for i in tqdm(range(len(list_site)), desc=\"Calculating Pearson Correlation\"):\n",
    "    site_i = list_site[i]\n",
    "    std_path = 'E:\\experiment\\DTR_AI_growth\\data\\ITRDB\\FZS_STD_crn\\\\'+ site_i + '.rwlcrn.csv'\n",
    "    df_rwl_i = pd.read_csv(std_path, index_col=0)\n",
    "    year_i = df_rwl_i.index.to_list()\n",
    "    list_range = [i for i in range(1901, 2016)]\n",
    "    intersection = list(set(year_i) & set(list_range))\n",
    "    if len(intersection)>= 10:\n",
    "        std_i = df_rwl_i.loc[intersection,'std'].to_list()\n",
    "        dtr_i = dtr.set_index('site').loc[site_i,[f'{year}' for year in intersection]]\n",
    "        dtr_i1=dtr.set_index('site').loc[site_i,[f'{year}' for year in intersection]]\n",
    "        dtr_i = np.array(dtr_i).reshape(-1, 1)\n",
    "        model = LinearRegression()\n",
    "        model.fit(dtr_i, std_i)\n",
    "        list_β_dtr.append(model.coef_)\n",
    "        slope, intercept, r_value, p_value, std_err= scipy.stats.linregress(dtr_i1.to_list(), std_i)\n",
    "        list_R.append(r_value)\n",
    "        list_sites.append(site_i)\n",
    "\n",
    "df_β_dtr = pd.DataFrame(list_β_dtr)\n",
    "df_β_dtr.columns = ['β']\n",
    "df_β_dtr.insert(0,'site',list_sites)\n",
    "df_β_dtr.insert(1,'r_squared',list_R)\n",
    "df_β_dtrcs = pd.merge(df_siteEPS_M_S1,df_β_dtr,on='site')\n",
    "grouped = df_β_dtrcs.groupby('AI_Class')\n",
    "anova_results_dr = {}\n",
    "anova_results_wr = {}\n",
    "group_humid = grouped.get_group('Humid')\n",
    "group_arid = grouped.get_group('Arid')\n",
    "group_humid95 = calculate_confidence_interval(group_humid, 'β')\n",
    "group_arid95 = calculate_confidence_interval(group_arid, 'β')\n",
    "group_95_dtr = pd.concat([group_humid95,group_arid95],axis=0)\n",
    "group_95_dtr['Climate factors'] = 'dtr'\n",
    "ue\n",
    "f_statistic_dr, p_value_dr = f_oneway(group_humid['β'], group_arid['β'])\n",
    "anova_results_dr['β'] = {'F-statistic': f_statistic_dr, 'p-value': p_value_dr}\n",
    "\n",
    "for key, value in anova_results_dr.items():\n",
    "    print(f\"{key}: F-statistic: {value['F-statistic']}, p-value: {value['p-value']}\")\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "plt.figure(figsize=(4,3.5),dpi=100)\n",
    "palette=[(0/255, 92/255, 230/255),(255/255, 0/255, 0/255)]\n",
    "alpha = 0.5 \n",
    "sns.boxplot(x=\"AI_Class\", y=\"β\", data=group_95_dtr,palette=palette\n",
    "            ,  fill=False, gap=.2, boxprops=dict(alpha=alpha)\n",
    "            , whiskerprops=dict(alpha=alpha)\n",
    "            , capprops=dict(alpha=alpha), medianprops=dict(alpha=alpha))\n",
    "plt.axhline(0, color='black', linestyle='--',linewidth=.6)\n",
    "plt.yticks(np.arange(-0.4, 0.5, 0.2)) \n",
    "plt.legend().set_visible(False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('β DTR-Growth',fontsize=18)\n",
    "plt.text(0.5, 0.37, '***', ha='center', va='center')\n",
    "plt.text('Humid', 0.33,  f'n= {len(group_humid95)}', ha='center', va='center')\n",
    "plt.text('Arid', 0.33,  f'n= {len(group_arid95)}', ha='center', va='center')\n",
    "plt.savefig('FigS7b.jpg',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367b889-6f8d-4870-b554-377949338952",
   "metadata": {},
   "outputs": [],
   "source": [
    "scPDSI = pd.read_csv('annual_scPDSI.csv').dropna()\n",
    "list_site = pd.merge(df_siteEPS_M_S1,scPDSI,on='site')['site']\n",
    "list_sites = []\n",
    "list_β_scPDSI = []\n",
    "for i in tqdm(range(len(list_site)), desc=\"Calculating Pearson Correlation\"):\n",
    "    site_i = list_site[i]\n",
    "    std_path = 'E:\\experiment\\DTR_AI_growth\\data\\ITRDB\\FZS_STD_crn\\\\'+ site_i + '.rwlcrn.csv'\n",
    "    df_rwl_i = pd.read_csv(std_path, index_col=0)\n",
    "    year_i = df_rwl_i.index.to_list()\n",
    "    list_range = [i for i in range(1901, 2016)]\n",
    "    intersection = list(set(year_i) & set(list_range))\n",
    "    if len(intersection)>= 10:\n",
    "        std_i = df_rwl_i.loc[intersection,'std'].to_list()\n",
    "        scPDSI_i = scPDSI.set_index('site').loc[site_i,[f'{year}' for year in intersection]]\n",
    "        scPDSI_i = np.array(scPDSI_i).reshape(-1, 1)\n",
    "        model = LinearRegression()\n",
    "        model.fit(scPDSI_i, std_i)\n",
    "        list_β_scPDSI.append(model.coef_)\n",
    "        list_sites.append(site_i)\n",
    "\n",
    "df_β_scPDSI = pd.DataFrame(list_β_scPDSI)\n",
    "df_β_scPDSI.columns = ['β']\n",
    "df_β_scPDSI.insert(0,'site',list_sites)\n",
    "df_β_scPDSIcs = pd.merge(df_siteEPS_M_S1,df_β_scPDSI,on='site')\n",
    "grouped = df_β_scPDSIcs.groupby('AI_Class')\n",
    "anova_results_dr = {}\n",
    "anova_results_wr = {}\n",
    "group_humid = grouped.get_group('Humid')\n",
    "group_arid = grouped.get_group('Arid')\n",
    "group_humid95 = calculate_confidence_interval(group_humid, 'β')\n",
    "group_arid95 = calculate_confidence_interval(group_arid, 'β')\n",
    "\n",
    "group_95_scPDSI = pd.concat([group_humid95,group_arid95],axis=0)\n",
    "group_95_scPDSI['Climate factors'] = 'scPDSI'\n",
    "f_statistic_dr, p_value_dr = f_oneway(group_humid['β'], group_arid['β'])\n",
    "anova_results_dr['β'] = {'F-statistic': f_statistic_dr, 'p-value': p_value_dr}\n",
    "for key, value in anova_results_dr.items():\n",
    "    print(f\"{key}: F-statistic: {value['F-statistic']}, p-value: {value['p-value']}\")\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "plt.figure(figsize=(4,3.5),dpi=100)\n",
    "palette=[(0/255, 92/255, 230/255),(255/255, 0/255, 0/255)]\n",
    "alpha = 0.5 \n",
    "sns.boxplot(x=\"AI_Class\", y=\"β\", data=group_95_scPDSI,palette=palette\n",
    "            ,  fill=False, gap=.2, boxprops=dict(alpha=alpha)\n",
    "            , whiskerprops=dict(alpha=alpha)\n",
    "            , capprops=dict(alpha=alpha), medianprops=dict(alpha=alpha))\n",
    "plt.axhline(0, color='black', linestyle='--',linewidth=.6)\n",
    "plt.yticks(np.arange(-0.2, 0.5, 0.2)) \n",
    "plt.legend().set_visible(False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('β scPDSI-growth',fontsize=18)\n",
    "plt.text(0.5, 0.37, '***', ha='center', va='center')\n",
    "plt.text('Humid', 0.33,  f'n= {len(group_humid95)}', ha='center', va='center')\n",
    "plt.text('Arid', 0.33,  f'n= {len(group_arid95)}', ha='center', va='center')\n",
    "plt.savefig('Fig.S7d.jpg',dpi=300, bbox_inches='tight')\n",
    "plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
