{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93faf7a5-4626-4457-9c6b-09d511a11a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as smy\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73a479-aadc-4326-bdff-48985c5ccffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scPDSI = pd.read_csv('annual_scPDSI.csv')\n",
    "df_pre = pd.read_csv('annual_pre.csv')\n",
    "df_temp = pd.read_csv('annual_temp.csv')\n",
    "df_tmax = pd.read_csv('annual_Tmax.csv')\n",
    "df_tmin = pd.read_csv('annual_Tmin.csv')\n",
    "df_dtr = pd.read_csv('annual_dtr.csv')\n",
    "df_pet = pd.read_csv('annual_pet.csv')\n",
    "df_sample = pd.read_csv('sample_site.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ed130-b74d-4ad8-91fe-6fa4c645d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dry_wet_years(df):\n",
    "    dry_years = {}\n",
    "    wet_years = {}\n",
    "\n",
    "    for site in df.index:\n",
    "        dry_years[site] = []\n",
    "        wet_years[site] = []\n",
    "\n",
    "        for year in df.columns:\n",
    "            value = df.loc[site, year]\n",
    "\n",
    "            if -4 < value < -0.5:\n",
    "                dry_years[site].append(year)\n",
    "            elif 0.5 < value < 4:\n",
    "                wet_years[site].append(year)\n",
    "\n",
    "    return dry_years, wet_years\n",
    "\n",
    "dry_years, wet_years = get_dry_wet_years(df_scPDSI.dropna().set_index('site'))\n",
    "def intersection_list_ordered(list1, list2):\n",
    "    result = [value for value in list1 if value in list2]\n",
    "\n",
    "    return result\n",
    "\n",
    "list1 = [1, 2, 3, 4, 5]\n",
    "list2 = [3, 4, 5, 6, 7]\n",
    "\n",
    "result = intersection_list_ordered(list1, list2)\n",
    "print(result)\n",
    "def remove_adjacent_years(years):\n",
    "    years.sort()\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(years):\n",
    "        if i < len(years) - 1 and years[i + 1] - years[i] <= 2:\n",
    "            while i < len(years) - 1 and years[i + 1] - years[i] <= 2:\n",
    "                i += 1\n",
    "        else:\n",
    "            result.append(years[i])\n",
    "        i += 1\n",
    "    \n",
    "    return result\n",
    "def calculate_confidence_interval(df, column):\n",
    "    lower_bound = np.percentile(df[column], 2.5)\n",
    "    upper_bound = np.percentile(df[column], 97.5)\n",
    "    df_95 = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    mean_value = np.mean(df_95[column])\n",
    "    print(\"95% Confidence Interval ({}): [{:.4f}, {:.4f}]\".format(column, lower_bound, upper_bound))\n",
    "    print(\"Mean ({}): {:.4f}\".format(column, mean_value))\n",
    "    return df_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6abee-806d-4b45-91c8-9aa1eeaa0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_Resistance = []\n",
    "list_Recovery = []\n",
    "list_site = []\n",
    "from tqdm import tqdm\n",
    "site_list =pd.merge(df_sample,df_scPDSI.dropna().reset_index(),on = 'site')['site'].to_list()\n",
    "for i in tqdm(range(len(site_list)), desc=\"Calculating Growth_loss\"):\n",
    "    site_i = site_list[i]\n",
    "    std_path = 'E:\\experiment\\DTR_AI_growth\\data\\ITRDB\\FZS_STD_crn\\\\'+ site_i + '.rwlcrn.csv'\n",
    "    df_rwl_i =pd.read_csv(std_path)\n",
    "    dry_years_i  = [int(year) for year in dry_years[site_i]]\n",
    "    dry_years_i_intersection = intersection_list_ordered(dry_years_i,df_rwl_i.index.to_list())\n",
    "    dry_years2 = remove_adjacent_years(dry_years_i_intersection)\n",
    "    \n",
    "    wet_years_i = [int(year) for year in wet_years[site_i]]\n",
    "    wet_years_i_intersection = intersection_list_ordered(wet_years_i,df_rwl_i.index.to_list())\n",
    "    RWI_n = df_rwl_i.loc[wet_years_i_intersection,'std'].mean()\n",
    "\n",
    "    dry_years2_Pre = [element - 2 for element in dry_years2]\n",
    "    dry_years2_Pre_intersection = intersection_list_ordered(dry_years2_Pre,df_rwl_i.index.to_list())\n",
    "    dry_years2_pos = [element + 2 for element in dry_years2]\n",
    "    dry_years2_pos_intersection = intersection_list_ordered(dry_years2_pos,df_rwl_i.index.to_list())\n",
    "\n",
    "    RWI_D = df_rwl_i.loc[dry_years2,'std'].mean()\n",
    "    \n",
    "    RWI_n = df_rwl_i.loc[wet_years_i_intersection,'std'].mean()#no-drought\n",
    "    RWI_Pre = df_rwl_i.loc[dry_years2_Pre_intersection,'std'].mean()\n",
    "    RWI_Post = df_rwl_i.loc[dry_years2_pos_intersection, 'std'].mean()\n",
    "    if RWI_n > RWI_D:\n",
    "        \n",
    "        Resistance = RWI_D /RWI_Pre\n",
    "        Recovery = RWI_Post / RWI_D\n",
    "        \n",
    "        list_Resistance.append(Resistance)\n",
    "        list_Recovery.append(Recovery)\n",
    "        list_site.append(site_i)\n",
    "df_rr = pd.DataFrame({'site':list_site,'Resistance':list_Resistance\n",
    "                     ,'Recovery':list_Recovery})\n",
    "cs1 = pd.merge(df_rr,df_sample,on = 'site').dropna()\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "import matplotlib.pyplot as plt\n",
    "grouped = cs1.groupby('AI_Class')\n",
    "anova_results_dr = {}\n",
    "anova_results_wr = {}\n",
    "group_humid = grouped.get_group('Humid')\n",
    "group_arid = grouped.get_group('Arid')\n",
    "group_arid95 = calculate_confidence_interval(group_arid, 'Recovery')\n",
    "group_humid95 = calculate_confidence_interval(group_humid, 'Recovery')\n",
    "df_merge95 = pd.concat([group_arid95,group_humid95],axis=0)\n",
    "f_statistic_dr, p_value_dr = f_oneway(group_arid95['Recovery'],group_humid95['Recovery'])\n",
    "anova_results_dr['Recovery'] = {'F-statistic': f_statistic_dr, 'p-value': p_value_dr}\n",
    "for key, value in anova_results_dr.items():\n",
    "    print(f\"{key}: F-statistic: {value['F-statistic']}, p-value: {value['p-value']}\")\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "colors = [(255/255, 0/255, 0/255),(0/255, 92/255, 230/255)]\n",
    "plt.figure(figsize=(5,4.5),dpi=100)\n",
    "#palette=['#8DCDD5','#E6846D']\n",
    "alpha = 0.5 \n",
    "sns.boxplot(x=\"AI_Class\", y=\"Recovery\", data=df_merge95\n",
    "            ,palette=colors,  fill=False, gap=.2, boxprops=dict(alpha=alpha)\n",
    "            , whiskerprops=dict(alpha=alpha)\n",
    "            , capprops=dict(alpha=alpha), medianprops=dict(alpha=alpha))\n",
    "plt.axhline(1, color='black', linestyle='--',linewidth=.6)\n",
    "plt.ylim(0.5,2.5)\n",
    "plt.yticks([0.5,1,1.5,2.0,2.5]) \n",
    "plt.legend().set_visible(False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Resilience',fontsize=18)\n",
    "plt.text(0.5, 1.8, '***', ha='center', va='center')\n",
    "plt.text('Humid', 0.55,  f'n = {len(group_humid95)}', ha='center', va='center')\n",
    "plt.text('Arid', 0.55,  f'n = {len(group_arid95)}', ha='center', va='center')\n",
    "plt.savefig('Fig3a.jpg',dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "df_species = pd.read_excel('40tree.xlsx')\n",
    "species_dict = dict(zip(df_species['Tree_Speci'], df_species['Clade']))\n",
    "df_merge95['Species_group'] = df_merge95['Tree_Speci'].map(species_dict)\n",
    "df_merge95['Species_group'] = df_merge95['Species_group'].fillna('Unknown')\n",
    "df_merge95['log_aiv3']= np.log10(df_merge95['ai_v3'])\n",
    "df_merge95['log_aiv3'].replace(-np.inf, np.nan, inplace=True)\n",
    "df_merge95.dropna(subset=['log_aiv3'], inplace=True)\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 14\n",
    "plt.rcParams[\"ytick.labelsize\"] = 14\n",
    "plt.figure(figsize=(5, 4.5))\n",
    "\n",
    "species_groups = df_merge95['Species_group'].unique()\n",
    "color_map = {\n",
    "    species_groups[0]: (0/255, 92/255, 230/255),\n",
    "    species_groups[1]: (255/255, 0/255, 0/255)\n",
    "}\n",
    "\n",
    "for species in species_groups:\n",
    "    df_group = df_merge95[df_merge95['Species_group'] == species]\n",
    "\n",
    "    r, p = pearsonr(df_group['log_aiv3'], df_group['Recovery'])\n",
    "    print(r)\n",
    "    X = df_group[['log_aiv3']]\n",
    "    y = df_group['Recovery']\n",
    "    X_with_const = sm.add_constant(X)  \n",
    "    model = sm.OLS(y, X_with_const).fit()\n",
    "    intercept, slope = model.params\n",
    "    predictions = model.get_prediction(X_with_const)\n",
    "    predicted_mean = predictions.predicted_mean\n",
    "    conf_int = predictions.conf_int()\n",
    "\n",
    "    plt.scatter(df_group['log_aiv3'], df_group['Recovery'], \n",
    "                alpha=0.08, label=f'{species} (r={r:.2f}, p={p:.2e})',\n",
    "                color=color_map[species])\n",
    "\n",
    "    plt.plot(df_group['log_aiv3'], predicted_mean, color=color_map[species], linestyle='-')\n",
    "\n",
    "    plt.fill_between(df_group['log_aiv3'], conf_int[:, 0], conf_int[:, 1], color=color_map[species], alpha=0.2)\n",
    "plt.ylim(0.5,2.5)\n",
    "plt.yticks([0.5,1, 1.5, 2,2.5])\n",
    "plt.xlabel('Log10(Aridity index)')\n",
    "plt.ylabel('Resilience')\n",
    "plt.legend(fontsize=12,loc=1)\n",
    "plt.grid(True)\n",
    "plt.savefig('Fig3b.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "df_biome = pd.read_csv('gl_Biome.csv')\n",
    "df95Recovery = pd.merge(df_biome,df_merge95.loc[:,('Recovery','site')],on='site')\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "plt.figure(figsize=(12, 6))\n",
    "alpha = 0.7 \n",
    "colors = [(0/255, 92/255, 230/255),(255/255, 0/255, 0/255)]\n",
    "sns.boxplot(x='Biome_Re', y='Recovery', hue='AI_Class', data=df95Recovery, palette=colors\n",
    "           ,  fill=False, gap=.2, boxprops=dict(alpha=alpha)\n",
    "            , whiskerprops=dict(alpha=alpha)\n",
    "            , capprops=dict(alpha=alpha), medianprops=dict(alpha=alpha))\n",
    "\n",
    "biomes = df95Recovery['Biome_Re'].unique()\n",
    "for biome in biomes:\n",
    "    if biome == 'Deserts':\n",
    "        continue \n",
    "    \n",
    "    dry = df95Recovery[(df95Recovery['Biome_Re'] == biome) & (df95Recovery['AI_Class'] == 'Arid')]['Recovery']\n",
    "    wet = df95Recovery[(df95Recovery['Biome_Re'] == biome) & (df95Recovery['AI_Class'] == 'Humid')]['Recovery']\n",
    "\n",
    "    t_stat, p_val = stats.ttest_ind(dry, wet, nan_policy='omit', equal_var=False)\n",
    "    print(biome)\n",
    "    print(t_stat)\n",
    "    print(p_val)\n",
    "\n",
    "    x1, x2 = biomes.tolist().index(biome) - 0.2, biomes.tolist().index(biome) + 0.2\n",
    "    y, h, col = 0.6, 0.02, 'k' \n",
    "    \n",
    "    if np.isfinite(y):\n",
    "        plt.plot([x1, x1, x2, x2], [y, y + h, y + h, y], lw=1.5, c=col)\n",
    "        significance = ''\n",
    "        if p_val < 0.001:\n",
    "            significance = '***'\n",
    "        elif p_val < 0.01:\n",
    "            significance = '**'\n",
    "        elif p_val < 0.05:\n",
    "            significance = '*'\n",
    "        \n",
    "        plt.text((x1 + x2) * .5, y + h, f'{significance}', ha='center', va='bottom', color=col)\n",
    "    n_dry = len(dry)\n",
    "    n_wet = len(wet)\n",
    "    plt.text(biomes.tolist().index(biome)- 0.25, y - 0.1, f'n = {n_wet}', ha='center', va='center', color='blue')\n",
    "    plt.text(biomes.tolist().index(biome)+ 0.25 , y - 0.1, f'n = {n_dry}', ha='center', va='center', color='red')\n",
    "    \n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('')\n",
    "plt.ylim(0.3,2.5)\n",
    "plt.yticks([0.5,1.0,1.5,2.0,2.5])\n",
    "plt.ylabel('Resilience')\n",
    "plt.legend(title='Region')\n",
    "plt.savefig('Fig3c.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "df95Recovery['Latitude_bin'] = pd.cut(df95Recovery['Latitude'], bins=np.arange(-90, 91, 1))\n",
    "latitude_stats = df95Recovery.groupby('Latitude_bin')['Recovery'].agg(['mean', 'sem']).reset_index()\n",
    "slope, intercept, r_value, p_value, std_err = linregress(latitude_stats.dropna()['mean']\n",
    "                                                         , latitude_stats.dropna()['Latitude_bin'].apply(lambda x: x.mid))\n",
    "fig, ax = plt.subplots(figsize=(3, 6))\n",
    "ax.axvline(x=1, color='gray', linestyle='--')  # 添加零值虚线\n",
    "ax.plot(latitude_stats['mean'], latitude_stats['Latitude_bin'].apply(lambda x: x.mid), marker='o', linestyle='-', color='black')\n",
    "ax.fill_betweenx(latitude_stats['Latitude_bin'].apply(lambda x: x.mid), \n",
    "                 latitude_stats['mean'] - 1.96 * latitude_stats['sem'], \n",
    "                 latitude_stats['mean'] + 1.96 * latitude_stats['sem'], \n",
    "                 color='orange', alpha=0.3)\n",
    "ax.plot(latitude_stats.dropna()['mean'], intercept + slope * latitude_stats.dropna()['mean'],color='blue')\n",
    "ax.set_xlabel('Resilience')\n",
    "ax.set_ylabel('Latitude (°)')\n",
    "ax.text(0.05, 0.35, f'r ={r_value:.2f}\\np ={p_value:.2e}', transform=ax.transAxes\n",
    "        , fontsize=14, verticalalignment='top')\n",
    "plt.ylim(15,75)\n",
    "ax.grid(True)\n",
    "plt.savefig('FigS5b.jpg',dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "df95Recovery.to_csv('Recovery95.csv',index=False)\n",
    "Gymnosperms = df95Recovery[df95Recovery['Species_group']=='Gymnosperms']\n",
    "Angiosperms = df95Recovery[df95Recovery['Species_group']=='Angiosperms']\n",
    "f_statistic_dr, p_value_dr = f_oneway(Gymnosperms['Recovery'], Angiosperms['Recovery'])\n",
    "print(p_value_dr)\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "colors = [(255/255, 0/255, 0/255),(0/255, 92/255, 230/255)]\n",
    "plt.figure(figsize=(4,3.5),dpi=100)\n",
    "#palette=['#8DCDD5','#E6846D']\n",
    "alpha = 0.5 \n",
    "sns.boxplot(x=\"Species_group\", y=\"Recovery\", data=df95Recovery\n",
    "            ,palette=colors,  fill=False, gap=.2, boxprops=dict(alpha=alpha)\n",
    "            , whiskerprops=dict(alpha=alpha)\n",
    "            , capprops=dict(alpha=alpha), medianprops=dict(alpha=alpha))\n",
    "plt.axhline(1, color='black', linestyle='--',linewidth=.6)\n",
    "plt.ylim(0.5,2.5)\n",
    "plt.yticks([0.5,1,1.5,2.0,2.5]) \n",
    "plt.legend().set_visible(False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Resilience',fontsize=18)\n",
    "plt.text(0.5, 0.6, '**', ha='center', va='center')\n",
    "plt.text('Gymnosperms', 0.6,  f'n= {len(Gymnosperms)}', ha='center', va='center')\n",
    "plt.text('Angiosperms', 0.6,  f'n= {len(Angiosperms)}', ha='center', va='center')\n",
    "plt.savefig('FigS4b.jpg',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
