{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e1099-d842-45fe-9bff-c20de0adca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f6ca55-53af-449c-a64d-4ad3b440ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv('sample_site.csv')\n",
    "df_scPDSI = pd.read_csv('annual_scPDSI.csv')\n",
    "df_pre = pd.read_csv('annual_pre.csv')\n",
    "df_temp = pd.read_csv('annual_temp.csv')\n",
    "df_tmax = pd.read_csv('annual_Tmax.csv')\n",
    "df_tmin = pd.read_csv('annual_Tmin.csv')\n",
    "df_dtr = pd.read_csv('annual_dtr.csv')\n",
    "df_pet = pd.read_csv('annual_pet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057b1d5-8d67-49c7-b7b0-efd0245efee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dry_wet_years(df):\n",
    "    dry_years = {}\n",
    "    wet_years = {}\n",
    "\n",
    "    for site in df.index:\n",
    "        dry_years[site] = []\n",
    "        wet_years[site] = []\n",
    "\n",
    "        for year in df.columns:\n",
    "            value = df.loc[site, year]\n",
    "\n",
    "            if -4 < value < -0.5:\n",
    "                dry_years[site].append(year)\n",
    "            elif 0.5 < value < 4:\n",
    "                wet_years[site].append(year)\n",
    "\n",
    "    return dry_years, wet_years\n",
    "\n",
    "dry_years, wet_years = get_dry_wet_years(df_scPDSI.dropna().set_index('site'))\n",
    "def get_dry_wet_years(df):\n",
    "    dry_years = {}\n",
    "    wet_years = {}\n",
    "\n",
    "    for site in df.index:\n",
    "        dry_years[site] = []\n",
    "        wet_years[site] = []\n",
    "\n",
    "        for year in df.columns:\n",
    "            value = df.loc[site, year]\n",
    "\n",
    "            if -4 < value < -0.5:\n",
    "                dry_years[site].append(year)\n",
    "            elif 0.5 < value < 4:\n",
    "                wet_years[site].append(year)\n",
    "\n",
    "    return dry_years, wet_years\n",
    "def calculate_row_means(df1,df2):\n",
    "    df_concat = pd.merge(df1,df2, on = 'site')\n",
    "    df_concat.loc[:,'1901':].mean(axis= 1)\n",
    "    return df_concat.loc[:,'1901':].mean(axis= 1).to_list()\n",
    "dry_years, wet_years = get_dry_wet_years(df_scPDSI.dropna().set_index('site'))\n",
    "list_Growth_loss = []\n",
    "from tqdm import tqdm\n",
    "site_list =pd.merge(df_sample,df_scPDSI.dropna().reset_index(),on = 'site')['site'].to_list()\n",
    "for i in tqdm(range(len(site_list)), desc=\"Calculating Growth_loss\"):\n",
    "    site_i = site_list[i]\n",
    "    std_path = 'E:\\experiment\\DTR_AI_growth\\data\\ITRDB\\FZS_STD_crn\\\\'+ site_i + '.rwlcrn.csv'\n",
    "    df_rwl_i =pd.read_csv(std_path)\n",
    "    #Growth-no-drought\n",
    "    wet_years_i  = [int(year) for year in wet_years[site_i]]\n",
    "    wet_years_i_intersection = intersection_list_ordered(wet_years_i,df_rwl_i.index.to_list())\n",
    "    Growth_no_dry = df_rwl_i.loc[wet_years_i_intersection,'std'].mean()\n",
    "    #Growth-drought\n",
    "    dry_years_i  = [int(year) for year in dry_years[site_i]]\n",
    "    dry_years_i_intersection = intersection_list_ordered(dry_years_i,df_rwl_i.index.to_list())\n",
    "    Growth_dry = df_rwl_i.loc[dry_years_i_intersection,'std'].mean()\n",
    "    Growth_loss = (Growth_dry-Growth_no_dry)/Growth_no_dry\n",
    "    list_Growth_loss.append(Growth_loss)\n",
    "cs = pd.merge(df_sample,df_scPDSI.dropna().reset_index()['site'],on = 'site')\n",
    "scpDSI_mean = calculate_row_means(cs,df_scPDSI)\n",
    "pre_mean = calculate_row_means(cs,df_pre)\n",
    "temp_mean = calculate_row_means(cs,df_temp)\n",
    "tmax_mean = calculate_row_means(cs,df_tmax)\n",
    "tmin_mean = calculate_row_means(cs,df_tmin)\n",
    "dtr_mean = calculate_row_means(cs,df_dtr)\n",
    "pet_mean = calculate_row_means(cs,df_pet)\n",
    "mean_Groth_loss = {'site':site_list,'Growth_loss':list_Growth_loss,'pre_mean':pre_mean,\n",
    "           'scpDSI_mean':scpDSI_mean,'temp_mean':temp_mean,'tmax_mean':tmax_mean,\n",
    "                  'tmin_mean':tmin_mean,'dtr_mean':dtr_mean,'pet_mean':pet_mean\n",
    "                  }\n",
    "def calculate_confidence_interval(df, column):\n",
    "    lower_bound = np.percentile(df[column], 2.5)\n",
    "    upper_bound = np.percentile(df[column], 97.5)\n",
    "    df_95 = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    mean_value = np.mean(df_95[column])\n",
    "    print(\"95% Confidence Interval ({}): [{:.4f}, {:.4f}]\".format(column, lower_bound, upper_bound))\n",
    "    print(\"Mean ({}): {:.4f}\".format(column, mean_value))\n",
    "    return df_95\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "import matplotlib.pyplot as plt\n",
    "grouped = df_merge.groupby('AI_Class')\n",
    "anova_results_dr = {}\n",
    "anova_results_wr = {}\n",
    "group_humid = grouped.get_group('Humid')\n",
    "group_arid = grouped.get_group('Arid')\n",
    "group_humid95 = calculate_confidence_interval(group_humid, 'Growth_loss')\n",
    "group_arid95 = calculate_confidence_interval(group_arid, 'Growth_loss')\n",
    "df_merge95 = pd.concat([group_humid95,group_arid95],axis=0)\n",
    "f_statistic_dr, p_value_dr = f_oneway(group_humid95['Growth_loss'], group_arid95['Growth_loss'])\n",
    "anova_results_dr['Growth_loss'] = {'F-statistic': f_statistic_dr, 'p-value': p_value_dr}\n",
    "for key, value in anova_results_dr.items():\n",
    "    print(f\"{key}: F-statistic: {value['F-statistic']}, p-value: {value['p-value']}\")\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "colors = [(255/255, 0/255, 0/255),(0/255, 92/255, 230/255)]\n",
    "plt.figure(figsize=(5,4.5),dpi=100)\n",
    "#palette=['#8DCDD5','#E6846D']\n",
    "alpha = 0.5 \n",
    "sns.boxplot(x=\"AI_Class\", y=\"Growth_loss\", data=df_merge95\n",
    "            ,palette=colors,  fill=False, gap=.2, boxprops=dict(alpha=alpha)\n",
    "            , whiskerprops=dict(alpha=alpha)\n",
    "            , capprops=dict(alpha=alpha), medianprops=dict(alpha=alpha))\n",
    "plt.axhline(0, color='black', linestyle='--',linewidth=.6)\n",
    "plt.ylim(-0.6,0.3)\n",
    "plt.yticks([-0.6,-0.3,0,0.3]) \n",
    "plt.legend().set_visible(False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Growth loss',fontsize=18)\n",
    "plt.text(0.5, -0.5, '***', ha='center', va='center')\n",
    "plt.text('Humid', -0.5,  f'n= {len(group_humid95)}', ha='center', va='center')\n",
    "plt.text('Arid', -0.5,  f'n= {len(group_arid95)}', ha='center', va='center')\n",
    "plt.savefig('Fig3b.jpg',dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "df_merge_95['log_ai_v3']= np.log10(df_merge_95['ai_v3'])\n",
    "df_merge_95['log_ai_v3'].replace(-np.inf, np.nan, inplace=True)\n",
    "df_merge_95.dropna(subset=['log_ai_v3'], inplace=True)\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "plt.figure(figsize=(5,4.5),dpi=100)\n",
    "species_groups = df_merge_95['Species_group'].unique()\n",
    "\n",
    "\n",
    "color_map = {\n",
    "    species_groups[0]: (0/255, 92/255, 230/255),\n",
    "    species_groups[1]: (255/255, 0/255, 0/255)\n",
    "}\n",
    "for species in species_groups:\n",
    "    df_group = df_merge_95[df_merge_95['Species_group'] == species]\n",
    "    r, p = pearsonr(df_group['log_ai_v3'], df_group['Growth_loss'])\n",
    "    X = df_group[['log_ai_v3']]\n",
    "    y = df_group['Growth_loss']\n",
    "\n",
    "    X_with_const = sm.add_constant(X) \n",
    "    model = sm.OLS(y, X_with_const).fit()\n",
    "    intercept, slope = model.params\n",
    "    predictions = model.get_prediction(X_with_const)\n",
    "    predicted_mean = predictions.predicted_mean\n",
    "    conf_int = predictions.conf_int()\n",
    "    plt.scatter(df_group['log_ai_v3'], df_group['Growth_loss'], \n",
    "                alpha=0.06, label=f'{species} (r={r:.2f}, p={p:.2e})',\n",
    "                color=color_map[species])\n",
    "    plt.plot(df_group['log_ai_v3'], predicted_mean, color=color_map[species], linestyle='-')\n",
    "    plt.fill_between(df_group['log_ai_v3'], conf_int[:, 0], conf_int[:, 1], color=color_map[species], alpha=0.2)\n",
    "plt.yticks([-0.5, 0, 0.5])\n",
    "plt.xlim(-1,1)\n",
    "plt.xlabel('Log10(Aridity index)')\n",
    "plt.ylabel('Growth loss',fontsize=18)\n",
    "plt.legend(fontsize=10,loc=1)\n",
    "plt.grid(True)\n",
    "plt.savefig('FigS3c.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362fe311-84f9-4d7b-bc55-d7e5e900a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "def calculate_vpd(temperature, actual_vap):\n",
    "    s_vap = 6.108 * math.exp((17.27 * temperature) / (237.3 + temperature))\n",
    "    vpd = s_vap - actual_vap\n",
    "    return vpd\n",
    "temperature = 21.350001\n",
    "actual_vap = 13.516667  \n",
    "vpd = calculate_vpd(temperature, actual_vap)\n",
    "print(f\"VPD: {vpd} kPa\")\n",
    "df_Temp = pd.read_csv('annual_temp.csv').set_index('site')\n",
    "df_svp = pd.read_csv('annual_vap.csv').set_index('site')\n",
    "def calculate_vpd1(df_Temp, df_svp):\n",
    "    def saturation_vapor_pressure(temp):\n",
    "        return 6.108 * math.exp((17.27 * temp) / (237.3 + temp))\n",
    "    df_VPD = pd.DataFrame(index=df_Temp.index, columns=df_Temp.columns)\n",
    "    for site in df_Temp.index:\n",
    "        for year in df_Temp.columns:\n",
    "            temp = df_Temp.loc[site, year]\n",
    "            actual_vap = df_svp.loc[site, year]\n",
    "            s_vap = saturation_vapor_pressure(temp)\n",
    "            vpd = s_vap - actual_vap\n",
    "            df_VPD.loc[site, year] = vpd\n",
    "    \n",
    "    return df_VPD\n",
    "df_VPD = calculate_vpd1(df_Temp, df_svp)\n",
    "df_VPD.to_csv('annual_VPD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089e85c-2571-4653-a502-46c46240196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NPP = pd.read_csv('npp_values.csv')\n",
    "df_NPP_Npp = df_NPP.filter(regex='_01_01_Npp$')\n",
    "rename_dict = {col: col.split('_')[0] for col in df_NPP_Npp.columns}\n",
    "df_NPP_Npp = df_NPP_Npp.rename(columns=rename_dict)\n",
    "df_selected = pd.concat([df_NPP_Npp, df_NPP['site']], axis=1)\n",
    "df_sample_NPP = pd.merge(df_sample,df_selected,on='site')\n",
    "list_Growth_loss = []\n",
    "list_siteNPP = []\n",
    "from tqdm import tqdm\n",
    "site_list =pd.merge(df_sample_NPP,df_scPDSI.dropna().reset_index(),on = 'site')['site'].to_list()\n",
    "year2020 = list(range(2001, 2016))\n",
    "for i in tqdm(range(len(site_list)), desc=\"Calculating Growth_loss\"):\n",
    "    site_i = site_list[i]\n",
    "    wet_years_i  = [int(year) for year in wet_years[site_i]]\n",
    "    wet_years_i_intersection = intersection_list_ordered(wet_years_i,year2020)\n",
    "    wet_years_i_intersection_NPP= [str(year) for year in wet_years_i_intersection]\n",
    "    Growth_no_dry = df_sample_NPP.set_index('site').loc[site_i,wet_years_i_intersection_NPP].mean()\n",
    "    #Growth-drought\n",
    "    dry_years_i  = [int(year) for year in dry_years[site_i]]\n",
    "    dry_years_i_intersection = intersection_list_ordered(dry_years_i,year2020)\n",
    "    dry_years_i_intersection_NPP = [str(year) for year in dry_years_i_intersection]\n",
    "    Growth_dry = df_sample_NPP.set_index('site').loc[site_i,dry_years_i_intersection_NPP].mean()\n",
    "    Growth_loss = (Growth_no_dry-Growth_dry)/Growth_no_dry\n",
    "    list_Growth_loss.append(Growth_loss)\n",
    "    list_siteNPP.append(site_i)\n",
    "df_npp_GL = pd.DataFrame({'Growth_loss':list_Growth_loss,'site':list_siteNPP})\n",
    "df_npp_GL1 = pd.merge(df_npp_GL,df_sample,on='site').dropna()\n",
    "def calculate_confidence_interval(df, column):\n",
    "    lower_bound = np.percentile(df[column], 2.5)\n",
    "    upper_bound = np.percentile(df[column], 97.5)\n",
    "    df_95 = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    mean_value = np.mean(df_95[column])\n",
    "    print(\"95% Confidence Interval ({}): [{:.4f}, {:.4f}]\".format(column, lower_bound, upper_bound))\n",
    "    print(\"Mean ({}): {:.4f}\".format(column, mean_value))\n",
    "    return df_95\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "import matplotlib.pyplot as plt\n",
    "grouped = df_npp_GL1.groupby('AI_Class')\n",
    "anova_results_dr = {}\n",
    "anova_results_wr = {}\n",
    "group_humid = grouped.get_group('Humid')\n",
    "group_arid = grouped.get_group('Arid')\n",
    "group_humid95 = calculate_confidence_interval(group_humid, 'Growth_loss')\n",
    "group_arid95 = calculate_confidence_interval(group_arid, 'Growth_loss')\n",
    "df_merge95 = pd.concat([group_humid95,group_arid95],axis=0)\n",
    "\n",
    "f_statistic_dr, p_value_dr = f_oneway(group_humid95['Growth_loss'], group_arid95['Growth_loss'])\n",
    "anova_results_dr['Growth_loss'] = {'F-statistic': f_statistic_dr, 'p-value': p_value_dr}\n",
    "for key, value in anova_results_dr.items():\n",
    "    print(f\"{key}: F-statistic: {value['F-statistic']}, p-value: {value['p-value']}\")\n",
    "df_species = pd.read_excel('40tree.xlsx')\n",
    "species_dict = dict(zip(df_species['Tree_Speci'], df_species['Clade']))\n",
    "df_merge95['Species_group'] = df_merge95['Tree_Speci'].map(species_dict)\n",
    "df_merge95['Species_group'] = df_merge95['Species_group'].fillna('Unknown')\n",
    "df_merge95['log_ai_v3']= np.log10(df_merge95['ai_v3'])\n",
    "df_merge95['log_ai_v3'].replace(-np.inf, np.nan, inplace=True)\n",
    "df_merge95.dropna(subset=['log_ai_v3'], inplace=True)\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "##### 设置图形大小\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "plt.figure(figsize=(5,4.5),dpi=100)\n",
    "\n",
    "# 获取唯一的物种组\n",
    "species_groups = df_merge95['Species_group'].unique()\n",
    "\n",
    "# 定义颜色蓝色'#8DCDD5','#E6846D'(255/255, 127/255, 127/255),(190/255, 210/255, 255/255)\n",
    "color_map = {\n",
    "    species_groups[0]: (0/255, 92/255, 230/255),\n",
    "    species_groups[1]: (255/255, 0/255, 0/255)\n",
    "}\n",
    "\n",
    "for species in species_groups:\n",
    "    df_group = df_merge95[df_merge95['Species_group'] == species]\n",
    "\n",
    "    r, p = pearsonr(df_group['log_ai_v3'], df_group['Growth_loss'])\n",
    "\n",
    "    X = df_group[['log_ai_v3']]\n",
    "    y = df_group['Growth_loss']\n",
    "\n",
    "    X_with_const = sm.add_constant(X)  \n",
    "    model = sm.OLS(y, X_with_const).fit()\n",
    "\n",
    "    intercept, slope = model.params\n",
    "\n",
    "    predictions = model.get_prediction(X_with_const)\n",
    "    predicted_mean = predictions.predicted_mean\n",
    "    conf_int = predictions.conf_int()\n",
    "\n",
    "    plt.scatter(df_group['log_ai_v3'], df_group['Growth_loss'], \n",
    "                alpha=0.06, label=f'{species} (r={r:.2f}, p={p:.2e})',\n",
    "                color=color_map[species])\n",
    "\n",
    "    plt.plot(df_group['log_ai_v3'], predicted_mean, color=color_map[species], linestyle='-')\n",
    "\n",
    "    plt.fill_between(df_group['log_ai_v3'], conf_int[:, 0], conf_int[:, 1], color=color_map[species], alpha=0.2)\n",
    "plt.yticks([-0.5, 0, 0.5])\n",
    "plt.xlim(-1,1)\n",
    "plt.xlabel('Log10(Aridity index)')\n",
    "plt.ylabel('Growth loss',fontsize=18)\n",
    "plt.legend(fontsize=10,loc=1)\n",
    "plt.grid(True)\n",
    "plt.savefig('FigS3b.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "dfITRDB = pd.read_csv('gl_Biome.csv')\n",
    "ITRDB=dfITRDB.loc[:,('Growth_loss','site')]\n",
    "ITRDB.columns=['Growth_lossITRDB','site']\n",
    "MODIS = df_merge95.loc[:,('Growth_loss','site')]\n",
    "MODIS.columns=['Growth_lossMODSI','site']\n",
    "cs1 = pd.merge(ITRDB,MODIS,on='site')\n",
    "X = cs1['Growth_lossMODSI']\n",
    "y = cs1['Growth_lossITRDB']\n",
    "X = sm.add_constant(X)  \n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "conf_int = model.conf_int(alpha=0.05)\n",
    "predictions_summary_frame = model.get_prediction(X).summary_frame(alpha=0.05)\n",
    "mse = mean_squared_error(y, predictions)\n",
    "r2 = r2_score(y, predictions)\n",
    "p_values = model.pvalues\n",
    "plt.figure(figsize=(5, 4.5))\n",
    "plt.scatter(cs1['Growth_lossMODSI'], cs1['Growth_lossITRDB'], color=(0/255, 92/255, 230/255) ,alpha=0.2,)\n",
    "plt.plot(cs1['Growth_lossMODSI'], predictions, color='red')\n",
    "plt.fill_between(cs1['Growth_lossMODSI'], \n",
    "                 predictions_summary_frame['mean_ci_lower'], \n",
    "                 predictions_summary_frame['mean_ci_upper'], \n",
    "                 color='red', alpha=0.2)\n",
    "plt.yticks([-0.2,0,0.2,0.4])\n",
    "plt.xticks([-0.2,0,0.2,0.4])\n",
    "plt.xlabel('Growth losses calculated by MODIS')\n",
    "plt.ylabel('Growth loss calculated by ITRDB')\n",
    "plt.text(0.05, 0.99, f'R² = {r2:.2f}\\nMSE = {mse:.2f}\\np-value = {p_values[1]:.2e}', \n",
    "         transform=plt.gca().transAxes, fontsize=16, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS3a.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986e9cb-34c4-4165-b03a-3ade62cd5cca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
